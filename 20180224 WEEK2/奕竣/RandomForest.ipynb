{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind_empleado\n",
      "((1000000, 1), (929615, 1))\n",
      "Time is 31.84\n",
      "pais_residencia\n",
      "((1000000, 2), (929615, 2))\n",
      "Time is 30.62\n",
      "sexo\n",
      "((1000000, 3), (929615, 3))\n",
      "Time is 31.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "((1000000, 4), (929615, 4))\n",
      "Time is 27.44\n",
      "ind_nuevo\n",
      "((1000000, 5), (929615, 5))\n",
      "Time is 21.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antiguedad\n",
      "((1000000, 6), (929615, 6))\n",
      "Time is 27.30\n",
      "nomprov\n",
      "((1000000, 7), (929615, 7))\n",
      "Time is 40.67\n",
      "segmento\n",
      "((1000000, 8), (929615, 8))\n",
      "Time is 40.38\n",
      "((1000000, 8), (1000000, 24))\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/xingobar/random-forest-classifier/code\n",
    "# Original Version - Private score: 0.0232244; Public score: 0.0230549\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "\n",
    "# 選取需要的欄位\n",
    "targetcols = ['ncodpers', 'ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\n",
    "       'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1',\n",
    "       'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n",
    "       'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n",
    "       'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n",
    "       'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n",
    "       'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
    "       'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1']\n",
    "\n",
    "dtype_list = {'ind_cco_fin_ult1': 'float16',\n",
    "              'ind_deme_fin_ult1': 'float16',\n",
    "              'ind_aval_fin_ult1': 'float16',\n",
    "              'ind_valo_fin_ult1': 'float16',\n",
    "              'ind_reca_fin_ult1': 'float16',\n",
    "              'ind_ctju_fin_ult1': 'float16',\n",
    "              'ind_cder_fin_ult1': 'float16', \n",
    "              'ind_plan_fin_ult1': 'float16',\n",
    "              'ind_fond_fin_ult1': 'float16', \n",
    "              'ind_hip_fin_ult1': 'float16',\n",
    "              'ind_pres_fin_ult1': 'float16', \n",
    "              'ind_nomina_ult1': 'float16', \n",
    "              'ind_cno_fin_ult1': 'float16',\n",
    "              'ncodpers': 'int64',\n",
    "              'ind_ctpp_fin_ult1': 'float16',\n",
    "              'ind_ahor_fin_ult1': 'float16',\n",
    "              'ind_dela_fin_ult1': 'float16',\n",
    "              'ind_ecue_fin_ult1': 'float16',\n",
    "              'ind_nom_pens_ult1': 'float16',\n",
    "              'ind_recibo_ult1': 'float16',\n",
    "              'ind_deco_fin_ult1': 'float16',\n",
    "              'ind_tjcr_fin_ult1': 'float16', \n",
    "              'ind_ctop_fin_ult1': 'float16',\n",
    "              'ind_viv_fin_ult1': 'float16',\n",
    "              'ind_ctma_fin_ult1': 'float16'}       \n",
    "\n",
    "# 挑選的因子\n",
    "feature_cols = [\"ind_empleado\",\"pais_residencia\",\"sexo\",\n",
    "                \"age\", \"ind_nuevo\", \"antiguedad\", \"nomprov\",\n",
    "                \"segmento\"]\n",
    "\n",
    "train_file = 'train_ver2.csv'\n",
    "test_file = 'test_ver2.csv'\n",
    "train_size = 13647309\n",
    "nrows = 1000000\n",
    "start_idx = train_size - nrows\n",
    "\n",
    "# 資料處理工程（補值等資料清理動作）\n",
    "for idx,col in enumerate(feature_cols):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train = pd.read_csv(train_file,usecols=[col])\n",
    "    test = pd.read_csv(test_file,usecols=[col])\n",
    "    print(col)\n",
    "    ### data preprocessing\n",
    "    if col == 'age':\n",
    "        train[col] = pd.to_numeric(train[col],errors='coerce')\n",
    "        test[col] = pd.to_numeric(test[col],errors='coerce')\n",
    "        \n",
    "        train.loc[train.age < 18,\"age\"]  = train.loc[(train.age >= 18) & (train.age <= 30),\"age\"].mean(skipna=True)\n",
    "        test.loc[test.age > 100,\"age\"] = test.loc[(test.age >= 30) & (test.age <= 100),\"age\"].mean(skipna=True)\n",
    "        \n",
    "        train['age'].fillna(train['age'].mean(),inplace=True)\n",
    "        test['age'].fillna(test['age'].mean(),inplace=True)\n",
    "        train['age'] = train['age'].astype(int)\n",
    "        test['age']= test['age'].astype(int)\n",
    "        \n",
    "        \n",
    "    elif col == 'ind_nuevo':\n",
    "       train.loc[train[col].isnull(),col] = 1\n",
    "       test.loc[test[col].isnull(),col] = 1\n",
    "    elif col == 'antiguedad':\n",
    "        train[col] = pd.to_numeric(train[col],errors='coerce')\n",
    "        test[col] = pd.to_numeric(test[col],errors = 'coerce')\n",
    "        train.loc[train[col].isnull(),col] = train[col].min()\n",
    "        train.loc[train[col] < 0 , col] = 0 \n",
    "        test.loc[test[col].isnull(),col] = test[col].min()\n",
    "        test.loc[test[col] <0 ,col] = 0\n",
    "    elif col =='nomprov':\n",
    "        train[col].fillna('Unknown',inplace=True)\n",
    "        test[col].fillna('Unknown',inplace=True)\n",
    "    elif col =='segmento':\n",
    "        train[col] = train[col].apply(lambda x:str(x).split('-')[0])\n",
    "        test[col] = test[col].apply(lambda x:str(x).split('-')[0])\n",
    "        train.loc[train[col].isnull(),col] = 'Unknown'\n",
    "        test.loc[test[col].isnull(),col] = 'Unknown'\n",
    "    else:\n",
    "        train[col].fillna(-999,inplace=True)\n",
    "        test[col].fillna(-999,inplace=True)\n",
    "    ##### \n",
    "    if train[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(train[col].values) + list(test[col].values))\n",
    "        temp_train = le.transform(list(train[col].values)).reshape(-1,1)[start_idx:,:]\n",
    "        temp_test = le.transform(list(test[col].values)).reshape(-1,1)\n",
    "    else:\n",
    "        temp_train = np.array(train[col]).reshape(-1,1)[start_idx:,:]\n",
    "        temp_test = np.array(test[col]).reshape(-1,1)\n",
    "    if idx == 0:\n",
    "        x_train = temp_train.copy()\n",
    "        x_test = temp_test.copy()\n",
    "    else:\n",
    "        x_train = np.hstack([x_train,temp_train])\n",
    "        x_test = np.hstack([x_test,temp_test])\n",
    "    print(x_train.shape,x_test.shape)\n",
    "    print('Time is %0.2f' %(time.time() - start_time))\n",
    "    del train\n",
    "    del test\n",
    "\n",
    "y_train = pd.read_csv(train_file,usecols = targetcols,dtype=dtype_list)\n",
    "last_instance = y_train.drop_duplicates(y_train,keep='last')\n",
    "\n",
    "y_train = np.array(y_train.fillna(0)).astype('int')[start_idx:,1:]\n",
    "print(x_train.shape,y_train.shape)\n",
    "\n",
    "\n",
    "#Original Version\n",
    "\n",
    "print('Running Model...')\n",
    "clf = RandomForestClassifier(n_estimators=10,\n",
    "                             max_depth=10,\n",
    "                             n_jobs=-1,\n",
    "                             random_state=42)\n",
    "\n",
    "clf.fit(x_train,y_train)\n",
    "del x_train\n",
    "del y_train\n",
    "print('Predicting....')\n",
    "## [n_sample , n_class]\n",
    "y_pred = np.array(clf.predict_proba(x_test))[:,:,1].T ## [n_class,n_sample]\n",
    "del x_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*-----------------------------------------------------------*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#forest = RandomForestClassifier()\n",
    "\n",
    "#parameters = {'n_estimators': [10, 20, 30], # The number of trees in the forest.\n",
    "#              'criterion': ['entropy', 'gini'],     \n",
    "#              'max_depth': [5, 10, 15, 20],        # The maximum depth of the tree. \n",
    "#              'min_samples_split': [2, 5, 10, 15, 20]  # The minimum number of samples required to split an internal node.\n",
    "#             }\n",
    "#acc_scorer = make_scorer(accuracy_score)\n",
    "#grid = GridSearchCV(forest, parameters, scoring = acc_scorer)\n",
    "#grid = grid.fit(x_train, y_train)\n",
    "#print grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#forest = grid.best_estimator_\n",
    "#forest.fit(x_train, y_train)\n",
    "#y_pred = np.array(forest.predict_proba(x_test))[:,:,1].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*-----------------------------------------------------------*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 挑選產品出來（調整程式的寫法）\n",
    "prod_cols = ['ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\n",
    "       'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1',\n",
    "       'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n",
    "       'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n",
    "       'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n",
    "       'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n",
    "       'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
    "       'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the last instance dictionary ....\n"
     ]
    }
   ],
   "source": [
    "print('Getting the last instance dictionary ....')\n",
    "last_instance.fillna(0,inplace=True) # 25 cols\n",
    "recommendation_product = {}\n",
    "#targetcols = np.array(targetcols)  # 25 cols\n",
    "targetcols = np.array(prod_cols)    # 24 cols\n",
    "\n",
    "for idx,row_val in last_instance.iterrows():\n",
    "    \n",
    "    ids = row_val['ncodpers']\n",
    "    used_product = set(targetcols[np.array(row_val[1:]) == 1])\n",
    "    recommendation_product[ids] = used_product\n",
    "del last_instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission ....\n",
      "Finish. Time is 972.46\n"
     ]
    }
   ],
   "source": [
    "# 產出最後推薦的結果\n",
    "print('Submission ....')\n",
    "## [n_class , n_sample]\n",
    "pred = np.argsort(y_pred,axis=1) ## sort probability by axis 1 and return index\n",
    "#print(pred)\n",
    "pred = np.fliplr(pred) \n",
    "test_ids = np.array(pd.read_csv(test_file,usecols=['ncodpers'])['ncodpers'])\n",
    "final_preds = []\n",
    "for idx,predicted in enumerate(pred):\n",
    "    ids = test_ids[idx]\n",
    "    top_product = targetcols[predicted]\n",
    "    used_product = recommendation_product.get(ids,[])\n",
    "    new_top_product = []\n",
    "    for product in top_product:\n",
    "        if product not in used_product:\n",
    "            new_top_product.append(product)\n",
    "        if len(new_top_product) == 7:\n",
    "            break\n",
    "    final_preds.append(' '.join(new_top_product))\n",
    "result = pd.DataFrame({'ncodpers':test_ids,'added_products':final_preds})\n",
    "result.to_csv('submission_rf.csv',index=False)\n",
    "print('Finish. Time is %0.2f' %(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 5.05561173e-05 6.78685501e-01 ... 3.19945951e-01\n",
      "  3.26134827e-01 7.45981937e-01]\n",
      " [0.00000000e+00 3.22190898e-06 5.29963456e-01 ... 8.19260053e-02\n",
      "  8.54169331e-02 2.21892458e-01]\n",
      " [0.00000000e+00 0.00000000e+00 8.32436537e-01 ... 7.14754885e-03\n",
      "  7.76483872e-03 3.48085941e-02]\n",
      " ...\n",
      " [2.47025573e-05 0.00000000e+00 5.14387493e-01 ... 3.41761417e-02\n",
      "  3.68284130e-02 9.71346157e-02]\n",
      " [5.63063063e-05 0.00000000e+00 4.90819560e-01 ... 4.28741850e-02\n",
      "  4.42364563e-02 1.08082880e-01]\n",
      " [2.67903576e-05 1.19329187e-05 4.96919719e-01 ... 2.22155332e-02\n",
      "  3.30110823e-02 7.62527653e-02]]\n"
     ]
    }
   ],
   "source": [
    "print y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23  2 19 ...  1  5  0]\n",
      " [ 2 23  4 ...  9  1  0]\n",
      " [ 2 23  4 ... 20  1  0]\n",
      " ...\n",
      " [ 2 23 12 ...  9  0  1]\n",
      " [ 2 23  4 ...  9  0  1]\n",
      " [ 2  7 23 ...  9  0  1]]\n"
     ]
    }
   ],
   "source": [
    "print pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
