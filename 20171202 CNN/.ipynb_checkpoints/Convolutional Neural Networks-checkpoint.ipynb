{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Convolutional Neural Networks<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷積神經網路（Convolutional Neural Networks，CNN）\n",
    "在這個章節中，我們將學習：\n",
    "#### 什麼是卷積神經網路（Convolutional Neural Networks，CNN），比較類神經網路和人腦的圖像辨識。\n",
    "#### 分成幾個部份去將卷積類神經網路進行拆解，課程將**卷積神經網路（Convolutional Neural Networks，CNN）** 拆成四個步驟，其中第一個部分又分成兩個部分：\n",
    "+ Step1 **Convolution Operation(卷積運算)**：其中包含**feature detectors(特徵檢測器)**，**filters(濾波器)**，**feature maps(特徵圖)**。<br>\n",
    "+ Step1(B) **RELU-Layer(線性整流單元層)**：介紹**Rectified Linear Unit(線性整流單元 &ensp; RELU)**並且討論圖像辨識(image recognition)為什麼需要非線性的過程。<br>\n",
    "+ Step2 **Pooling(池化)**：介紹什麼是池化以及為什麼需要池化?<br>\n",
    "+ Step3 **Flattening(平化)**：介紹平化的觀念。<br>\n",
    "+ Step4 **Full Connection(全連結)**：介紹全連結層（fully connected layers）的觀念。<br>\n",
    "最後課程中進行了彙總和補充的&ensp; **Softmax** &ensp; 與 &ensp; **Cross-Entropy**。<hr>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what are convolutional neural networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/CNN1_1.PNG)\n",
    "首先，這是一張人臉圖，當你用曲線右邊去看這張圖，你會認為這是面對右邊的人在斜眼看你，如果用左邊來看，你會覺得是一個人在面對你，在人腦處理圖像或影像的時候，是根據看到的特徵去做辨識，這就是人腦在辨識一張圖的邏輯，你不會接收全部的資訊，你會被部分特徵所吸引下判斷，而找尋特徵去做辨識就是圖像辨識的概念。<br>\n",
    "卷積神經網路（Convolutional Neural Networks，CNN）最簡單的運作架構如圖所示：<br>\n",
    "![](images/CNN1.PNG)\n",
    "輸入了一張圖像，透過CNN獲得標籤(Label)，輸出圖像的分類。\n",
    "![](images/CNN2.PNG)\n",
    "還有一個臉部表情與動作的例子，給CNN一個真實微笑的人的圖像，他會辦別這個人是開心的，而給一張皺著眉頭的臉就判斷她心情差，CNN可以辨識情感，根據提取到的特徵去進行辨識。\n",
    "![](images/CNN3.PNG)\n",
    "用一個基本程度的例子說明如何辨識這些特徵\n",
    "有兩張圖像，一張是黑白像素也被稱為[灰階](https://zh.wikipedia.org/wiki/%E7%81%B0%E5%BA%A6%E5%9B%BE%E5%83%8F)(Gray scale)的2$*$2的2維陣列的圖像，一張是彩色圖像也被稱為RGB及CMYK，這裡講的是[RGB圖像](https://zh.wikipedia.org/wiki/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F)而每一個的像素是介於0到255之間，共256階。<br>\n",
    "<span style=\"color:red\">補充</span> ：\n",
    "+ 灰階（Gray scale）：用於顯示的灰階圖像通常用每個採樣像素8 bit來保存，這樣可以有256種灰階（8bits就是2的8次方=256），每個點由從 0 (黑色)到 255 (白色)的亮度值來表現，其中間的值來表現不同程度的灰。\n",
    "+ RGB 圖像：代表紅(Red)-綠(Ggreen)-藍(Blue)也就是色光三原色，代表圖像上的每個點用一個「紅色」色階，一個「綠色」色階和一個「藍色」色階表示。人類能辨別的每種顏色都能用紅，綠和藍組合來表現，每一個顏色通道都有 256 種可能的亮度程度。\n",
    "灰度圖像和RGB 圖像最本質的區別就是它們「<span style=\"color:red\">顏色</span> 」的數量：一個灰度圖像只有一個；一個 RGB 圖像有三個。一個 RGB 圖像可以認為是三個灰度圖像的疊加，一個為紅色，一個為綠色，另一個為藍色。\n",
    "![](images/CNN4.PNG)\n",
    "笑臉圖可以轉換成計算機術語表示，而在這邊先忽略灰階，用最簡單的方式表達，黑色用1表示，白色用0表示，就會變成第三張圖，接下來我們會利用第三張圖的部份去當作我們CNN的輸入圖像，更多的細節可以參考作者提供的[論文](paper/Gradient-Based Learning Applied to Document Recognition.pdf)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷積類神經網路拆解：\n",
    "+ Step1 **Convolution Operation(卷積運算)**<br>\n",
    "+ Step1(B) **RELU-Layer(線性整流單元層)**<br>\n",
    "+ Step2 **Pooling(池化)**<br>\n",
    "+ Step3 **Flattening(平化)**<br>\n",
    "+ Step4 **Full Connection(全連結)**<br>\n",
    "### Step1 **Convolution Operation(卷積運算)**<Br>\n",
    "\\begin{align} (f \\ast g)(t)  \\overset{def}{=} \\int_{-\\infty}^{\\infty} f(\\tau)g(t-\\tau)d\\tau\\end{align}   \n",
    "這是卷積(convolution)的數學算式，不多贅述，如果有興趣可以參考作者推薦的[論文](paper/CNN.pdf)，直接用一個簡單的例子來說明怎麼計算。<br>\n",
    "補充[參考文獻](https://chtseng.wordpress.com/2017/09/12/%E5%88%9D%E6%8E%A2%E5%8D%B7%E7%A9%8D%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF/)\n",
    "![](images/CNN5.PNG)\n",
    "這個$input$圖像是延續前面的簡單範例，以及有一個3$*$3的陣列稱為特徵檢測器(feature detectors)或是卷積核(kernel)或是濾波器(filters)，但不一定要3$*$3，也可以5$*$5或7$*$7等不同的設定，但最為常見的還是3$*$3。<br>\n",
    "進行卷積運算時，會將特徵檢測器放入圖像的<span style=\"color:red\">局部</span>，進行特徵和圖像局部的相符程度計算，只要將兩者對應的各個像素上的值相乘後加總。而每次移動過濾器的距離稱為**間隔（stride）**，在這裡的間隔為**1個像素**，而間隔的移動也是可以改變的。<br>\n",
    "最右邊的圖被稱為特徵圖(feature maps)或是激活圖(activation map)，當透過特徵檢測器的轉換後，原本的$input$圖像會縮小，而縮小的幅度會受到**間隔**的影響，間隔越大圖像會縮得更小，特徵檢測器在卷積過程中最重要的一點就是要讓圖變小因為這樣可以更快比較更容易處理圖像，但問題是我們會損失資訊，但特徵檢測器的目的就是要檢測那些特徵的圖像是不可或缺的，因為特徵檢測器上有固定的圖像特徵，那在特徵圖上越大的數值代表更匹配這個圖案特徵，像數值4的那個部分就是完美對應此特徵檢測器。<br>\n",
    "在本章節開頭時我們討論如何示辨識圖像，在真實世界中我們不可能去看每一個單一的像素，我們在辨識是否為人像是去看鼻子 眼睛等特徵去辨識，而不會去看全部的特徵，不會去接收全部的資訊。\n",
    "![](images/CNN6.PNG)\n",
    "在回到我們的input 圖像，我們因為有不同的濾波器而產生了很多不同的特徵圖，後續會訓練模型找出對於某些分類重要的特徵圖。<br>\n",
    "接著作者在這邊介紹了幾種在[GIMP](https://docs.gimp.org/en/plug-in-convmatrix.html)的濾波器會對原本的圖像做處理分別是：銳化(Sharpen)、模糊(Blur)、邊緣增強(Edge enhance)、邊緣檢測(Edge detect)、凸印(Emboss)，是一個免費的工具用來調整你的圖像。<br>\n",
    "卷積的重點在初始圖像利用特徵檢測器產出特徵圖找到特徵，特徵是神經網路用來檢測與辨識圖像的工具。<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step1(B) **RELU-Layer(線性整流單元層)**<br>\n",
    "  在卷積層之後，會進入線性整流單元(Rectified Linear Unit，ReLU)，這個部分就是利用前面ANN提到的整流函數(Rectified Function)，有些作者會講將卷積層與線性整流單元拆分成兩個步驟，而這裡就合併一起來看。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 - Building the CNN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
